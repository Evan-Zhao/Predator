\label{sec:detection}

We first describe \Predator{}'s false sharing detection mechanism, which comprises both compiler and runtime system
components. Section~\ref{sec:prediction} then explains how \Predator{} predicts potential false sharing based on a single execution.

\subsection{Overview}
\label{sec:overview}

False sharing occurs when two threads
simultaneously access logically independent data in the same cache line, and where at least one of the accesses is a write.
For the purposes of exposition, we assume that each thread runs on a distinct core with its own private cache.

We observe that 
if a thread writes a cache line after other threads have 
accessed the same cache line, this write operation most likely causes at least one cache invalidation. It is this invalidation traffic that leads to performance degradation due to false sharing. To identify the root cause of such traffic due to false sharing, \Predator{} tracks cache invalidations of all cache lines, and ranks the severity of performance degradation of any detected false sharing problems according to the number of cache invalidations. 
 

% The design tradeoff of choosing compiler instrumentation has been discussed in Section~\ref{sec:instrumentationtradeoff}. 

To track cache invalidations, \Predator{} relies on compiler instrumentation to track accesses to memory. While a compiler can easily identify read or write accesses, it cannot know how and when those instructions are being executed, since that depends on a specific execution, input, and runtime environment.

Therefore, \Predator{} combines compiler instrumentation with a runtime system to track cache invalidations. The compiler
instruments memory accesses with calls to the runtime system that notify it when an access occurs (see Section~\ref{sec:compiler}), and the runtime system collects and analyzes these accesses to detect and report false sharing (see Section~\ref{sec:runtime}).

\subsection{Compiler Instrumentation}
\label{sec:compiler}

\Predator{} relies on LLVM to perform instrumentation at the intermediate representation level~\cite{llvm}.
It traverses all functions one by one and searches for memory accesses to global and heap variables.  For each memory access, \Predator{} inserts a function call to invoke the runtime system with the memory access address and access type (read or write). \Predator{} currently omits accesses to stack variables by default because stack variables are normally used for thread local storage and therefore do not normally introduce false sharing. However, instrumentation on stack variables
can always be turned on if desired.

The instrumentation pass is placed at the very end of the LLVM
optimization passes so that only those memory accesses surviving all previous LLVM optimization passes are instrumented.  This technique, which can drastically reduce the number of instrumentation calls, is similar to the one used by AddressSanitizer~\cite{Addresssanitizer}.

\subsection{Runtime System}
\label{sec:runtime}

\Predator{}'s runtime system collects every memory access via the functions calls inserted by the compiler's instrumentation phase. It analyzes possible cache invalidations due to possibly interleaved reads and writes. Finally, \Predator{} precisely reports any performance-degrading false sharing problems it finds.  For global variables involved in false sharing, \Predator{} reports their name, address and size; for heap
objects, \Predator{} reports the callsite stack for their allocations, their address and size. In addition, \Predator{} provides word granularity access information for those cache lines involved in false sharing, including which threads accessed which words.  This information can further help users diagnose and fix false sharing instances.

\subsubsection{Tracking Cache Invalidations}
\Predator{} only reports those global variables or heap objects on cache lines with a large number of cache invalidations. It is critical that \Predator{} track cache invalidations precisely in order to provide accurate reports of the location of false sharing instances.
\Predator{} achieves this goal by maintaining a two entry cache history table for every cache line.  In this table,
each entry has two fields: the thread ID and access type (read or write). The thread ID is used to identify the origin of each access. As stated earlier, only accesses from different threads can cause cache invalidations.

\begin{comment}
\begin{table}
\centering
  \begin{tabular}{ l | r }
    \hline
    {Thread ID} & {Type of Access} \\ \hline
    \hline
     &   \\ \hline
     &   \\ \hline
  \end{tabular}
  \caption{Two-entries-cache-history table for every cache line. \label{table:cachehistory}}
\end{table} 
\end{comment}

For every new access to a cache line $L$, \Predator{} checks $L$'s history table $T$ to decide whether there is a cache invalidation based on the following rules.  Note that table $T$ only has two statuses: full and not full.  There is no ``empty'' status since every cache invalidation should replace this table with the current write access.

\begin{itemize}
\item
  For a read access $R$, 
  \begin{itemize}
    \item
      If $T$ is full, there is no need to record this read access.
    \item
      If $T$ is not full and another existing entry has a different thread
      ID, then \Predator{} records this read and its thread by adding a new entry to the table. 
  \end{itemize}
\item
  For a write access $W$, 
  \begin{itemize}
    \item
      If $T$ is full, then $W$ can cause a cache invalidation since at least one of two existing entries has a different thread ID.
      After recording this invalidation, \Predator{} updates the
      existing entry with $W$ and its thread.
    \item
      If $T$ is not full,
      \Predator{} checks whether $W$ and the existing entry have the same thread ID. If
      so, $W$ cannot cause a cache invalidation, so \Predator{} updates the existing
      entry with $W$. Otherwise, \Predator{} identifies an invalidation on this line caused by $W$. 
      After recording this invalidation information, \Predator{} updates the
      existing entry with $W$ and its thread.
  \end{itemize}
\end{itemize}

\subsubsection{Reporting False Sharing}

Once cache lines with many cache invalidations have been detected,
\Predator{} needs to perform further analysis to differentiate actual false sharing from true sharing. 
True sharing, e.g., multiple threads updating the same counter in a cache line, can also cause many cache invalidations.

In order to report false sharing precisely and accurately,  
\Predator{} employs the following mechanisms:

\paragraph{Distinguishing False from True Sharing.} \Predator{} keeps track of access information for each word on those cache lines involved in false sharing: how many reads or writes to each word by which thread.  When a word is accessed by multiple threads, \Predator{} marks the origin of this word as a shared access and does not track threads for further accesses to it. This approach lets \Predator{} accurately distinguish false sharing from true sharing in the reporting phase.  It also helps diagnose where
actual false sharing occurs when there are multiple fields or multiple
objects in the same cache line, as this can greatly reduce the manual
effort required to fix the false sharing problems.

\paragraph{Callsite Tracking for Heap Objects.} In order to precisely report the origins of heap objects with false
sharing problems, \Predator{} maintains detailed information so it can report source code level information for each heap
object. To obtain callsite information, \Predator{} intercepts all memory allocations and de-allocations, and relies
on the \texttt{backtrace()} function in the \texttt{glibc} library to obtain the whole callsite stack.
\Predator{} also avoids pseudo false sharing (false positives) caused by memory reuse because it updates recording information at memory de-allocations for those objects without false sharing problems; heap objects involved in false 
sharing are never reused.

\paragraph{Optimizing Metadata Lookup.}
For every access, \Predator{} needs to look up the corresponding cache line's metadata 
in order to store detailed information or update access counters. Because this operation is so frequent,
 lookups need to be very efficient.
Like 
AddressSanitizer~\cite{Addresssanitizer} and other systems~\cite{qinzhaodetection,Valgrind},
\Predator{} uses a shadow memory mechanism to store metadata for every piece of application data. 
Thus, \Predator{} can compute and locate corresponding metadata directly via address arithmetic.

\paragraph{Custom Memory Allocation.} In order to efficiently support shadow memory, \Predator{} uses a predefined starting address and fixed size for its heap.  It also contains a custom memory allocator, which is built with Heap Layers~\cite{heaplayers} using a ``per-thread-heap'' mechanism similar to that used by Hoard~\cite{Hoard}.  In this allocator, memory allocations from different threads never occupy the same physical cache line, which automatically prevents false sharing among different objects.  However, using this custom memory allocator implies that false sharing caused by a memory allocator cannot be detected by \Predator{}. It is straightforward to solve such false sharing problems by using an allocator like Hoard that avoids this kind of false sharing.

 
\subsection{Optimizations}
\label{optimization}
Tracking every memory access can be extremely expensive.  
\Predator{} utilizes the following mechanisms to further reduce overhead.

\subsubsection{Threshold-Based Tracking Mechanism}
\label{sec:thresholdtracking}
\Predator{} aims to detect false sharing that significantly degrades performance. Since cache invalidations are the root cause of performance degradation and only writes 
can possibly introduce cache invalidations, 
cache lines with a small number of writes are never a significant performance bottleneck.
For this reason, \Predator{} only tracks cache invalidations
once the number of writes to a cache line crosses a
pre-defined threshold, which we refer to as the {\it TrackingThreshold}. 
Until this threshold is reached, \Predator{} only tracks the number of writes on a cache line 
while skipping tracking for reads.
This mechanism reduces runtime and memory overhead
at the same time.

\Predator{} maintains two arrays in shadow memory: 
{\it CacheWrites} tracks the number of memory writes to every cache line, and
{\it CacheTracking} tracks detailed information 
for each cache line once the number of writes on a cache line exceeds
the {\it TrackingThreshold}. 
If the threshold is not reached, there is no need to check the corresponding {\it CacheTracking} entry. 

\begin{figure}[!t]
\begin{lstlisting}
void HandleAccess(unsigned long addr, bool isWrite) {
 unsigned long cacheIndex = addr>>CACHELINE_SIZE_SHIFTS;
 CacheTrack *track = NULL;

 if (CacheWrites[cacheIndex] < TRACKING_THRESHOLD) {
  if (isWrite) {
   if (ATOMIC_INCR(&CacheWrites[cacheIndex]) 
       >= TRACKING_THRESHOLD) {
     track = allocCacheTrack();
     ATOMIC_CAS(&CacheTracking[cacheIndex], 0, track));
   }
  } 
 } else {
  track = CacheTracking[index];
  if (track) {
   // Track cache invalidations and detailed accesses
   track->handleAccess(addr, isWrite);
  }
 }
}
\end{lstlisting}
\caption{Pseudo-code for \Predator{}'s memory access instrumentation.\label{fig:algorithm}}
\end{figure}

To avoid expensive lock operations, \Predator{} uses atomic instruction to increment 
the {\it CacheWrites} counter for each cache line. 
Once the number of writes of a cache line reaches the predefined threshold,
\Predator{} allocates space to track detailed cache invalidations and word accesses.
\Predator{} also 
uses an atomic compare-and-swap to set the cache tracking address for this cache line in
the shadow mapping.
After {\it CacheWrites} on a cache line have crossed the {\it TrackingThreshold}, 
\Predator{} tracks all read and write accesses to this cache line.



\subsubsection{Selective Compiler Instrumentation}
\label{sec:selectinstrumentation}

\Predator{} relies on instrumentation to provide memory access information to the runtime system 
and detects false sharing based on the sequences of memory accesses to every cache line. 
The performance overhead of doing this is proportional to 
the degree of instrumentation: more 
instrumentation means higher performance overhead. \Predator{}'s design makes it possible to trade performance and accuracy as needed.

Currently, \Predator{} only adds instrumentation once for each type of memory access on each address 
in the same basic block. 
This selective instrumentation does not normally affect the effectiveness of detection. 
Because \Predator{} aims to detect cases of false sharing with many cache invalidations,
less tracking inside a basic block can induce fewer cache invalidations, 
but this does not affect the overall behavior of cache invalidations. 


To further improve performance,
\Predator{} could easily be extended to support more flexible instrumentation:
\begin{itemize}
\item
\Predator{} could selectively instrument both reads and writes or only writes.
Instrumenting only writes reduces overhead while detecting write-write false sharing, 
as \Sheriff{} does~\cite{sheriff}.
\item
\Predator{} can be set to instrument or skip specific code or data. 
For example, the user could provide a blacklist so that given modules,
functions or variables are not instrumented. 
Conversely, the user could provide a whitelist so that only specified functions or variables are instrumented. 
\end{itemize}

\subsubsection{Sampling Mechanism}
\label{sec:sample}
As Section~\ref{sec:thresholdtracking} describes, once the number of
writes on a cache line exceeds the {\it TrackingThreshold}, every
access must be tracked to store details such as word access
information, the access count, and the cache access history table
of this cache line.  When a cache line is involved in false or true
sharing, updating those counters can exacerbate the impact of sharing
on performance: not only is there an invalidation on an application
cache line, but there is also at least another cache invalidation
caused by updating the metadata of the corresponding cache lines.

To further reduce performance overhead, \Predator{} only samples the first specified
number of accesses of each sampling interval for problematic cache lines. 
Currently, \Predator{} maintains an access counter for each cache line
and only tracks the first $10,000$ out of every 1 million
accesses to a cache line (a 1\% sampling rate).

