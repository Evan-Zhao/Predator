\label{sec:detection}

\subsection{Overview}
%\Predator{} is a hybrid approach that combines the runtime system with compiler instrumentation.
\label{sec:overview}
As described in Section~\ref{sec:intro}, 
false sharing only occurs when two threads, running on two different cores that have private cache,
simultaneously access independent data in the same cache line.
In the remainder of this paper, we assume that {\it each thread runs on a 
distinct core with its own private cache}. 

Given this assumption, we observe that 
{\it if a thread writes a cache line after other threads have 
accessed the same cache line, this write operation most likely causes at least
a cache invalidation}. 
Based on this \textbf{basic observation}, \Predator{} tracks cache invalidations of all 
cache lines and ranks performance degrading severeness of false sharing problems 
according to the number of cache invalidations. 
% by keeping track of accesses from different threads. 
 
To track cache invalidations, it is important to trace memory accesses from different 
threads. 
On the one hand, without hardware support, it is difficult for runtime system itself to 
track read and write accesses efficiently, accurately and timely. 
For example, \Sheriff{} relies on memory protection mechanism and word-by-word
comparison to track accumulated write accesses. 
But there is no way to track read accesses with  
reasonable overhead~\cite{sheriff}. 
On the other hand, compiler can easily identify  
read or write accesses. However,
it is lack of the knowledge about when and how those instructions are being executed, 
which depends on a specific execution including input and runtime environment. 

Therefore, \Predator{} combines a runtime system with compiler instrumentation technique to track
cache invalidations: compiler instruments memory accesses so the runtime
system is notified when an access is executed (see Section~\ref{sec:compiler}),
and the runtime system is responsible for collecting and analyzing actual memory accesses 
to detect and report false sharing (see Section~\ref{sec:runtime}).

\subsection{Compiler Instrumentation}
\label{sec:compiler}

\Predator{} relies on LLVM to perform instrumentation on Intermediate Representation(IR) level~\cite{llvm}.
It traverses all functions one by one and 
searches for memory accesses on global and heap variables. 
For each memory access, \Predator{} instruments a function call to 
invoke the runtime system with memory access address and access type.
The reason why \Predator{} omits accesses to stack variables 
is that stack variables are normally used for thread local storage and
therefore do not introduce false sharing. However, instrumentation on stack
variables can always be turned on when necessary. 

The instrumentation pass is placed at the very end of LLVM optimization passes 
so that only those memory accesses surviving all previous 
LLVM optimization passes are instrumented. 
This  technique is very similar to the one used in AddressSanitizer~\cite{Addresssanitizer}.

\subsection{Runtime System}
\label{sec:runtime}
The runtime system of \Predator{} collects every memory access by handling 
those functions calls inserted during compiler instrumentation phase and analyzes
possible cache invalidations based on the basic observation discussed in Section~\ref{sec:overview}.
In the end, \Predator{} precisely reports performance-degrading false sharing problems:
For global variables involved in false sharing, their name, address and size
information are reported; For heap objects, the callsite stack for their allocations, 
their address and size information are reported.
In addition, \Predator{} provides word accesses information for those cache lines 
involved in false sharing, including which threads access which words. 
These information can further help 
users to diagnose where are problems and how to fix these problems.

\subsubsection{Tracking Cache Invalidations}
\Predator{} only reports those global variables or heap objects on 
those cache lines having a large amount of cache invalidations. 
Thus, it is critical to track cache invalidations effectively. 
\Predator{} achieves this goal by introducing a  
two-entries-cache-history table for each cache line, which is 
shown in Table~\ref{table:cachehistory}. 
In this table, each entry has two fields: thread ID and access type (read or write).
Thread ID is used to identify origins of an access. Based on our basic observation,
only accesses from a different thread can cause a possible cache invalidations. 

\begin{table}
\centering
  \begin{tabular}{ l | r }
    \hline
    {Thread ID} & {Type of Access} \\ \hline
    \hline
     &   \\ \hline
     &   \\ \hline
  \end{tabular}
  \caption{Two-entries-cache-history table for every cache line. \label{table:cachehistory}}
\end{table} 


For every new access on a cache line $L$, we check $L$'s history table
$T$ to decide whether there is a cache invalidation based on following rules.
Note that table $T$ only have two status, full and not full. 
There is no ``empty'' status since every cache invalidation should 
replace this table with current write access.

\begin{itemize}
\item
  For a read access $R$, 
  \begin{itemize}
    \item
      If $T$ is full, there is no need to record this read access.
    \item
      If $T$ is not full and another existing entry has a different thread
      ID, then we record this $R$ and its thread by filling a new entry in to the table. 
  \end{itemize}
\item
  For a write access $W$, 
  \begin{itemize}
    \item
      If $T$ is full, then $W$ can cause a cache invalidation since at least 
      one of two existing entries has a different thread ID.
      After recording this invalidation, we update 
      existing entry with $W$ and its thread.
    \item
      If $T$ is not full,
      we check whether $W$ and the existing entry has the same thread ID. If
      so, $W$ can not cause a cache invalidation, so we update the existing
      entry with $W$. Otherwise, we identify an invalidation on this line caused by $W$. 
      After recording this invalidation information, we update 
      existing entry with $W$ and its thread.
  \end{itemize}
\end{itemize}

\subsubsection{Reporting False Sharing}
After those cache lines with a large amount of cache invalidations are detected,
\Predator{} needs further analysis to differentiate actual false sharing from true sharing. 
True sharing, e.g. multiple threads updating 
the same counter in a cache line, can also causes a large amount of cache invalidations.

In order to report false sharing precisely and accurately,  
\Predator{} employs the following mechanisms. 
\begin{itemize}
\item
\Predator{} keeps track of access information for each word on those
cache lines involved in false sharing: 
how many reads or writes to each word by which thread. 
When a word is accessed by multiple threads,
we mark origin of this word as a shared access and do not track threads for further accesses 
on this word. This information 
allows \Predator{} to accurately distinguish false sharing from true sharing 
in the reporting phase.
It is also helpful to diagnose where 
actual false sharing occurs when there are multiple fields or multiple objects 
in the same cache line, thus can greatly reduce manual overhead to fix false sharing problems
correspondingly. 

\item
In order to precisely report origins of heap objects with false sharing problems, \Predator{}
keeps callsite information for each heap object and reports the source code level
information about each heap object. To obtain callsite information, \Predator{}
intercepts all memory allocations and de-allocations, and relies on \texttt{backtrace()} 
function of \texttt{glibc} library to obtain the whole callsite stack. 
\Predator{} also avoids pseudo false sharing (false positives) caused by memory re-usages 
by handling correspondingly in memory de-allocations, whereas those heap objects with false 
sharing is not re-used at all.

\item
For every access, \Predator{} should lookup corresponding cache line's metadata 
in order to store detailed information or update specific access counter necessarily.
Thus, these lookups should be implemented very efficient for performance reason. 
Similar to 
AddressSanitizer~\cite{Addresssanitizer} and other systems~\cite{qinzhaodetection}~\cite{Valgrind}. 
\Predator{} uses shadow memory mechanism to store metadata for every piece of application data. 
Thus, \Predator{} can compute and locate corresponding metadata immediately according to address of
an access.

\item
In order to support shadow memory mechanism, \Predator{} uses predefined starting address and 
fixed size for its heap. 
It also contains a customized memory allocator, which is built on 
Heaplayers~\cite{heaplayers} based on a ``per-thread-heap'' mechanism firstly introduced 
by Hoard~\cite{Hoard}. 
Memory allocations from different threads are never coming 
from the same physical cache line, which automatically avoids false sharing among different objects. 
However, using customized memory allocator 
brings a shortcoming that false sharing caused by memory 
allocator can not be detected by \Predator{}. 

\end{itemize} 
 
\subsection{Optimizations}
\label{optimization}
Tracking every memory access can be extremely expensive, thus 
\Predator{} utilizes the following mechanisms to further improve performance.

\subsubsection{Threshold-Based Tracking Mechanism}
\label{sec:thresholdtracking}
\Predator{} aims to detect performance degrading false sharing.
Since cache invalidations are the root cause of performance degradation and only writes 
can possibly introduce cache invalidations, 
those cache lines with a small amount of writes are never being our target.
For this reason, \Predator{} only tracks cache invalidations, reads and word accesses 
of a cache line after the number of writes on this cache line is above a
pre-defined threshold, called {\it Tracking-Threshould}. 
Before this threshold is reached, \Predator{} only tracks the number of writes on a cache line 
while skipping those reads operations. 
This mechanism helps to filter out
those impossible cache lines, reducing performance and memory overhead
in the same time.

In the actual implementation, \Predator{} maintains two arrays in shadow memory: 
{\it CacheWrites} is used to track the number of memory writes on every cache line;
{\it CacheTrackings} tracks detailed information 
on each cache line when the number of writes on a cache line is larger than
the {\it Tracking-Threshold}. 
If the threshold is not reached, there is no need to check corresponding {\it CacheTrackings}. 
Figure~\ref{fig:algorithm} illustrates the detailed mechanism.

\begin{figure}[!t]
\begin{lstlisting}
void HandleAccess(unsigned long addr, bool isWrite) {
 unsigned long cacheIndex=addr>>CACHELINE_SIZE_SHIFTS;
 cachetrack *track=NULL;

 if(CacheWrites[cacheIndex]<TRACKING_THRESHOLD) {
  if(isWrite) {
   if(ATOMIC_INCR(&CacheWrites[cacheIndex]) 
      ==TRACKING_THRESHOLD-1) {
    track=allocCacheTrack();
    ATOMIC_CAS(&CacheTrackings[cacheIndex],0,track));
   }
  } 
 }
 else {
  track=CacheTrackings[index]);
  if(track){
   // Track cache invalidations and detailed accesses
   track->handleAccess(addr, isWrite);
  }
 }
}
\end{lstlisting}
\caption{Pseudo-code to handle an access.\label{fig:algorithm}}
\end{figure}

To avoid expensive lock operations, \Predator{} uses atomic instruction to increment 
the {\it CacheWrites} counter for each cache line. 
When the number of writes of a cache line reaches the predefined threshold,
it allocates space to track detailed cache invalidations and word accesses.
For performance reason, \Predator{} also 
uses atomic \texttt{compare-and-swap} instruction to set cache tracking address for this cache line in
the shadow mapping.
After {\it CacheWrites} on a cache line reaches {\it Tracking-Threshold}, 
all read and write accesses on this cache line are started to be tracked.
%Cache invalidations are also computed based on cache line history table of corresponding
%cache line, shown in Table~\ref{table:cachehistory}. 


\subsubsection{Selective Compiler Instrumentation}
\Predator{} relies on instrumentation to provide memory access information to the runtime system 
and detects false sharing based on sequences of memory accesses on every cache line. 
Performance overhead of a specific program is always proportional to 
the amount of instrumentation: more 
instrumentation always means more performance overhead. 
Thus, \Predator{} provides a very flexible framework to instrument programs 
depending on performance requirements. 

Currently, \Predator{} only instruments once for one type of memory access on each address 
in the same basic block. 
We argue that this selective instrumentation does not affect the effectiveness of detection. 
Because \Predator{} targets to detect those false sharing with a large amount of cache invalidations,
less tracking of accesses inside one basic block can induce less cache invalidations 
but it won't affect the overall behavior of cache invalidations. 

% detection will not cause performance problem. 
For performance reason, 
\Predator{} can be easily extended to support more flexible instrumentation as follows:
\begin{itemize}
\item
\Predator{} can selectively instrument reads-and-writes or writes-only. 
For example, instrumenting writes-only can help to detect write-write type of false sharing, 
as \Sheriff{} does. 
\item
\Predator{} can be set to instrument or skip one specific kind of targets. 
For example, user can provide a black list so that those modules,
functions or variables are not instrumented. 
Also, user can provide a red list so that only specified functions or variables are instrumented. 
\end{itemize}

\subsubsection{Sampling Mechanism}
\label{sec:sample}
According to Section~\ref{sec:thresholdtracking}, 
when the number of writes on a cache line is larger than {\it Tracking-Threshold}, 
every access must be tracked to store word accesses information, update access counter and 
cache access history table of this cache line, etc. 
When a cache line actually has false sharing or true sharing problems inside,
updating those counters can exacerbate performance problems caused by false sharing or true
sharing: 
not only there is an invalidation on application cache line, 
but also there is
at least another cache invalidation caused by updating these metadata of corresponding cache lines.

To further reduce the performance overhead, \Predator{} only samples the first specified
number of accesses of each sampling interval for those problematic cache lines. 
%Note that we originally keep a global counter for all accesses and uses the number of 
%all accesses to compuate sample intervals. However, this creates 
%extereme performance overhead caused by cache invalidations of updating the same counter
%for all accesses. 
Currently, \Predator{} maintains an access counter for each cache line 
and only tracks the first $10000$ accesses out of  every 1 million accesses 
(sampling interval) on a cache line.
The sampling rate is only 1\% here.
By doing this, we might miss false sharing with an access pattern like this:
accesses causing false sharing must always 
happen exactly in other 99\% accesses for every 1 million accesses.
However, we believe that the possibility with this exact pattern is very low and \Predator{} 
should not miss any performance-degrading false sharing.  

\begin{comment}
\subsubsection{Updating-In-Place}
%During the development of \Predator{}, we discover over $2\times$ performance overhead for those benchmarks 
%without any false sharing problems. 

Originally, all memory accesses are instrumented with a library call to notify the runtime system. However, this creates
some unnecessary performance overhead from function calls and library calls. 
A library call invokes normal function call overhead plus another indirection overhead through a Global Offset Table (GOT) and 
Procedure Linkage Table (PLT).
This can introduce significant performance overhead for some simple logic listed in the following:
\begin{itemize}
\item
When total writes on a cache line is less than the pre-defined threshold, if an access is a write, 
\Predator{} simply incrementes the counter of writes for this cache line. If an access is a read,
\Predator{} does not do  anything. 
\item
When total writes on a cache line is larger than the pre-defined threshold, then this cache line is under 
tracking. As described in last section, \Predator{} only sample certain number of accesses (1\%) for every 
sample interval. Most accesses (99\%) only needs to increment an access counter of corresponding cache line.
\end{itemize}

These simple logic only invokes several circles of useful work, either checking or updating a counter. 
Thus, the overhead of function calls or library
calls can be much more than this. 
In order to avoid these overhead, \Predator{} implements these simple logic in places where these
memory accesses are instrumented. 
This brings another problem: how to choose shadow mapping addresses. 
We borrow the idea of AddressSanitizer~\cite{Addresssanitizer} by 
choosing these addresses statically. \Predator{} pre-allocated the address space between $0x40000000$ and
$0xC0000000$ for the heap. Also, \Predator{} chooses $0x200000000000$ as the starting address for the shadow mapping of cache writes 
$0x200080000000$ as the starting address for the shadow mapping of cache tracking. 
Also, \Predator{} intentionally stores the access counter in the first word of cache tracking so that 
those checking and updating can be executed in-place when an memory access is instrumented. 
\end{comment}
