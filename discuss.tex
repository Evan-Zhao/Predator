\label{sec:discussion}

\subsection{Instrumentation Selection}
\label{sec:instrumentationtradeoff}
Dynamic binary instrumentation and compiler-based instrumentation are two alternative approaches for performing instrumentation~\cite{Instrumentation}. They exhibit different tradeoffs of performance and generality. Dynamic instrumentation approaches, such as Valgrind~\cite{Valgrind}, Pin~\cite{Pin}, and DynamoRIO~\cite{DynamoRIO}, normally analyze the program's code just before execution in order to insert instrumentation. They introduce significant performance overhead, mostly caused by run-time encoding and decoding, but provide better generality because there is no need for recompilation. Compiler instrumentation inserts instrumentation in the compilation phase, which requires re-compilation of the source code. 
\Predator{} employs compiler-based instrumentation both because of its better performance its greater flexibility, as discussed in Section~\ref{sec:selectinstrumentation}.

\subsection{Important Factors on Effectiveness}
Different sampling rates do not affect effectiveness, which is discussed in Section~\ref{sec:sensitivity}. We discuss several other important factors here. 

\emph{Input} Different inputs can cause different executions of a program. If a specific input does not exercise the code with false sharing problems, \Predator{} definitely cannot detect them, sharing the same attribute as that of all dynamic tools. However, \Predator{} does generalize over inputs to find latent false sharing problems on those exercised code. When any reasonably representative set of inputs are exercised, as is required by any testing regime, \Predator{} can effectively detect false sharing.

\ emph{Input Size} Input size may affect detection results.  As discussed in Section~\ref{optimization}, \Predator{} introduces several threshold values to reduce the tracking overhead, which can be adjusted based on actual detection environment. If the input size is so small that it cannot generate enough false sharing events to pass those predefined thresholds, then the detection mechanism may not be triggered. Thus, \Predator{} can miss certain false sharing problems. However, fair large input size should be enough to trigger our detection mechanism. Actually, all evaluated applications take less than 150 seconds to expose false sharing problems inside. 

\ emph{Memory Hierarchy} Memory hierarchy of the underlying experimental machine cannot affect \Predator{}'s detection results. \Predator{} conservatively assumes that different threads are running on different cores and detects false sharing problems based on possible cache invalidations. \Predator{} does not attempt to obtain the actual cache invalidations of a program, which can depend on real memory hierarchy. Thus, \Predator{} does not bind to a specific machine, providing better generality than tools using hardware performance counters. A deeper hierarchy should only amplify the costs of false sharing, and thus exemplify the value of \Predator{}.

\subsection{Prediction Limitations} 
\Predator{} can accurately and precisely predict a false sharing problem even when it does not occur. But \Predator{} cannot predict a false sharing problem if the code with false sharing is not exercised at all. Also, \Predator{} may miss potential false sharing problems between two objects brought by a different compiler or memory allocator. 
